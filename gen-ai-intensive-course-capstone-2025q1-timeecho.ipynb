{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526bed77",
   "metadata": {
    "papermill": {
     "duration": 0.008395,
     "end_time": "2025-04-20T07:27:38.667644",
     "exception": false,
     "start_time": "2025-04-20T07:27:38.659249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TimeEcho: Immersive Historical Storytelling with GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e47efb",
   "metadata": {
    "papermill": {
     "duration": 0.007971,
     "end_time": "2025-04-20T07:27:38.683104",
     "exception": false,
     "start_time": "2025-04-20T07:27:38.675133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Welcome to **TimeEcho**, a generative AI-powered project that transforms historical events into immersive, first-person experiences.\n",
    "\n",
    "**Goal:**  \n",
    "To bring history to life using GenAI by combining retrieval-augmented generation (RAG), embeddings, image/audio generation, and persona-based narratives.\n",
    "\n",
    "**Key Capabilities Used:**\n",
    "- ðŸ” Retrieval-Augmented Generation (RAG)\n",
    "- ðŸ§  Gemini Embeddings\n",
    "- ðŸ–¼ï¸ Image & Visual Understanding\n",
    "- ðŸŽ™ï¸ Audio Narration with Emotion Cues\n",
    "- ðŸ§¾ Structured JSON Outputs\n",
    "- ðŸ” Few-Shot Prompting\n",
    "- ðŸ’¡ Dynamic Agents for Query Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaee388",
   "metadata": {
    "papermill": {
     "duration": 0.006835,
     "end_time": "2025-04-20T07:27:38.697040",
     "exception": false,
     "start_time": "2025-04-20T07:27:38.690205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Install Required Libraries & Import Dependencies\n",
    "\n",
    "We begin by installing essential packages for working with:\n",
    "- Gemini GenAI\n",
    "- Wikipedia data scraping\n",
    "- FAISS for vector search\n",
    "- Audio/image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a955c342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:27:38.712521Z",
     "iopub.status.busy": "2025-04-20T07:27:38.712127Z",
     "iopub.status.idle": "2025-04-20T07:27:55.905191Z",
     "shell.execute_reply": "2025-04-20T07:27:55.904170Z"
    },
    "papermill": {
     "duration": 17.202973,
     "end_time": "2025-04-20T07:27:55.907145",
     "exception": false,
     "start_time": "2025-04-20T07:27:38.704172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\r\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\r\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\r\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\r\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\r\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\r\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\r\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\r\n",
      "Collecting wikipedia-api\r\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.1.31)\r\n",
      "Building wheels for collected packages: wikipedia-api\r\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=bc8c869c3d0b3c81115909d7486e6fb54f64745e705023b89fceeb101f849d23\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\r\n",
      "Successfully built wikipedia-api\r\n",
      "Installing collected packages: wikipedia-api\r\n",
      "Successfully installed wikipedia-api-0.8.1\r\n",
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai \n",
    "!pip install wikipedia-api\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c394c328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:27:55.926584Z",
     "iopub.status.busy": "2025-04-20T07:27:55.926196Z",
     "iopub.status.idle": "2025-04-20T07:28:00.654512Z",
     "shell.execute_reply": "2025-04-20T07:28:00.653179Z"
    },
    "papermill": {
     "duration": 4.740386,
     "end_time": "2025-04-20T07:28:00.656696",
     "exception": false,
     "start_time": "2025-04-20T07:27:55.916310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wikipediaapi\n",
    "from typing import List, Dict, Any\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "import faiss\n",
    "import pickle\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30bc947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:28:00.685518Z",
     "iopub.status.busy": "2025-04-20T07:28:00.684939Z",
     "iopub.status.idle": "2025-04-20T07:28:03.104561Z",
     "shell.execute_reply": "2025-04-20T07:28:03.103425Z"
    },
    "papermill": {
     "duration": 2.431805,
     "end_time": "2025-04-20T07:28:03.106155",
     "exception": false,
     "start_time": "2025-04-20T07:28:00.674350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am ready to help create TimeEcho! \n",
      "\n",
      "To get started, I need a better understanding of what TimeEcho is.  Please tell me more about:\n",
      "\n",
      "*   **What is the purpose of TimeEcho?** What problem does it solve, or what need does it fulfill?\n",
      "*   **What are the core features of TimeEcho?**  What can users *do* with it?\n",
      "*   **Who is the target audience?** Who are you trying to reach with this?\n",
      "*   **What is the overall concept or vision for TimeEcho?**  Is it a website, a mobile app, a desktop program, something else entirely?\n",
      "*   **What technologies are you considering using?** (e.g., Python, JavaScript, React, databases, etc.)\n",
      "*   **What roles are you looking for me to fill?**  Are you looking for help with brainstorming, writing code, designing the UI, creating content, something else?\n",
      "\n",
      "The more information you give me, the better I can assist you.  I'm excited to hear about your project! Let's build something great.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_AI_Studio_key\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "response = model.generate_content(\"Hello, are you ready to help create TimeEcho?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a694344f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:28:03.125243Z",
     "iopub.status.busy": "2025-04-20T07:28:03.124882Z",
     "iopub.status.idle": "2025-04-20T07:28:03.132003Z",
     "shell.execute_reply": "2025-04-20T07:28:03.129805Z"
    },
    "papermill": {
     "duration": 0.018857,
     "end_time": "2025-04-20T07:28:03.133892",
     "exception": false,
     "start_time": "2025-04-20T07:28:03.115035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wikipedia_content(event_title):\n",
    "    \n",
    "    wiki = wikipediaapi.Wikipedia(\n",
    "        user_agent='TimeEcho-HistoricalProject/1.0 (Educational Project)',  # Replace with your info\n",
    "        language='en'\n",
    "    )\n",
    "    page = wiki.page(event_title)\n",
    "    \n",
    "    if page.exists():\n",
    "        return {\n",
    "            \"title\": page.title,\n",
    "            \"summary\": page.summary,\n",
    "            \"full_text\": page.text,\n",
    "            \"url\": page.fullurl\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03a7c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:28:03.154871Z",
     "iopub.status.busy": "2025-04-20T07:28:03.154540Z",
     "iopub.status.idle": "2025-04-20T07:28:03.162822Z",
     "shell.execute_reply": "2025-04-20T07:28:03.161839Z"
    },
    "papermill": {
     "duration": 0.020855,
     "end_time": "2025-04-20T07:28:03.164518",
     "exception": false,
     "start_time": "2025-04-20T07:28:03.143663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_doc_preparation(data):\n",
    "    data_list=[]\n",
    "    for each_event in data:\n",
    "        prompt=f'''Give me a JSON object in the following format for the event {each_event}, including persona-based perspectives, sensory details, historical context, and aftermath. Format it like a structured storytelling dataset.\n",
    "        Output structure :\n",
    "        {{\n",
    "            \"event_id\": \"unique_id\",\n",
    "            \"event_name\": \"Full Name of Event\",\n",
    "            \"time_period\": \"Date or Date Range\",\n",
    "            \"location\": \"Geographic Location\",\n",
    "            \"description\": \"Detailed 3-5 sentence description of what happened\",\n",
    "            \"key_figures\": [\"Person 1\", \"Person 2\", \"Person 3\"],\n",
    "            \"perspectives\": [\n",
    "                {{\n",
    "                    \"persona\": \"Type of Person Who Experienced This Event\",\n",
    "                    \"experience\": \"Their unique perspective and experiences\",\n",
    "                    \"daily_life\": \"How this person lived day-to-day during this time\",\n",
    "                    \"challenges\": \"Specific difficulties this person would have faced\"\n",
    "                }},\n",
    "                // Add 2-3 more perspectives\n",
    "            ],\n",
    "            \"sensory_details\": {{\n",
    "                \"sounds\": [\"Sound 1\", \"Sound 2\", \"Sound 3\", \"Sound 4\", \"Sound 5\"],\n",
    "                \"visuals\": [\"Visual Element 1\", \"Visual Element 2\", \"Visual Element 3\", \"Visual Element 4\", \"Visual Element 5\"],\n",
    "                \"environment\": [\"Environmental Detail 1\", \"Environmental Detail 2\", \"Environmental Detail 3\", \"Environmental Detail 4\", \"Environmental Detail 5\"]\n",
    "            }},\n",
    "            \"historical_context\": \"Broader historical context in 4-6 sentences\",\n",
    "            \"aftermath\": \"What happened as a result in 3-4 sentences\"\n",
    "        }}\n",
    "    \n",
    "    \n",
    "        Example1:\n",
    "        {{\n",
    "        \"event_id\": \"berlin_wall_fall\",\n",
    "        \"event_name\": \"Fall of the Berlin Wall\",\n",
    "        \"time_period\": \"1989-11-09\",\n",
    "        \"location\": \"Berlin, Germany\",\n",
    "        \"description\": \"The fall of the Berlin Wall on November 9, 1989, marked the beginning of the end of the Cold War and the division between East and West Berlin. After weeks of civil unrest, the East German government announced that its citizens could visit West Germany and West Berlin. Crowds gathered at the wall, and with no official orders on how to handle the situation, the guards opened the gates. Throughout the night, euphoric crowds swarmed the wall, climbing on top and beginning to chip away at the concrete structure that had divided the city for 28 years.\",\n",
    "        \"key_figures\": [\"GÃ¼nter Schabowski\", \"Erich Honecker\", \"Mikhail Gorbachev\"],\n",
    "        \"perspectives\": [\n",
    "            {{\n",
    "                \"persona\": \"East German Civilian\",\n",
    "                \"experience\": \"Living under the restrictions of the German Democratic Republic (GDR) with limited freedoms, particularly regarding travel and communication with family in West Berlin.\",\n",
    "                \"daily_life\": \"Waiting in long lines for basic goods, navigating government surveillance, and adapting to the economic challenges of East Germany.\",\n",
    "                \"challenges\": \"Risk of imprisonment for attempting to cross the border, limited access to information, political repression.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"persona\": \"Border Guard\",\n",
    "                \"experience\": \"Tasked with preventing East Germans from escaping to the West, facing moral dilemmas when confronted with desperate citizens.\",\n",
    "                \"daily_life\": \"Standing watch at checkpoints, following strict protocols, and potentially facing punishment for allowing unauthorized crossings.\",\n",
    "                \"challenges\": \"Balancing duty with personal ethics, potential guilt from preventing family reunifications, fear of consequences for disobeying orders.\"\n",
    "            }}\n",
    "        ],\n",
    "        \"sensory_details\": {{\n",
    "            \"sounds\": [\"Chants of 'Wir sind das Volk'\", \"Hammers chipping at concrete\", \"Border guards' radio communications\", \"Jubilant singing\", \"Honking car horns\"],\n",
    "            \"visuals\": [\"Graffiti-covered concrete wall\", \"Checkpoint Charlie guard towers\", \"Families reuniting\", \"East German Trabant cars queuing at border crossings\", \"People standing atop the wall\"],\n",
    "            \"environment\": [\"Cold November air\", \"Concrete dust\", \"Crowded streets\", \"Floodlights illuminating the wall\", \"Champagne bottles being opened\"]\n",
    "        }},\n",
    "        \"historical_context\": \"The Berlin Wall stood as a physical symbol of the Iron Curtain separating Western Europe and the Eastern Bloc during the Cold War. Built in 1961, it completely cut off West Berlin from East Berlin and East Germany. The wall was fortified with guard towers, anti-vehicle trenches, and a 'death strip' where guards were authorized to shoot escapees. By 1989, political changes in the Eastern Bloc, particularly in Hungary and Poland, created pressure for change in East Germany as well.\",\n",
    "        \"aftermath\": \"The reunification of Germany followed on October 3, 1990. The wall was gradually dismantled, with sections preserved as memorials. Germany faced substantial challenges in reintegrating the two economies and societies. The fall of the wall accelerated the collapse of communist regimes across Eastern Europe and ultimately led to the dissolution of the Soviet Union in 1991.\"\n",
    "        }}'''\n",
    "        response = model.generate_content(prompt)\n",
    "        data_list.append(json.loads(response.text.replace(\"```\",\"\").replace('json',\"\")))\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90462400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:28:03.210910Z",
     "iopub.status.busy": "2025-04-20T07:28:03.210602Z",
     "iopub.status.idle": "2025-04-20T07:29:44.890193Z",
     "shell.execute_reply": "2025-04-20T07:29:44.889231Z"
    },
    "papermill": {
     "duration": 101.691459,
     "end_time": "2025-04-20T07:29:44.892150",
     "exception": false,
     "start_time": "2025-04-20T07:28:03.200691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "list_of_events=[\"Fall of the Berlin Wall\",\"World War I\",'World War II','Indian Independence Movement','French Revolution',\"Fall of Constantinople\",'Cuban Missile Crisis','Fall of Rome',\"Renaissance\",'March on Washington',\"Boston Tea Party\",'Tiananmen Square Protests',\"D-Day Landings\",'Assassination of JFK','First War of Independence',\"Wright Brothers' First Flight\"]\n",
    "for each_event in list_of_events:\n",
    "    event=get_wikipedia_content(each_event)\n",
    "    data.append(event)\n",
    "data_list=[]\n",
    "data_list=rag_doc_preparation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251e6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:44.910767Z",
     "iopub.status.busy": "2025-04-20T07:29:44.910441Z",
     "iopub.status.idle": "2025-04-20T07:29:44.916101Z",
     "shell.execute_reply": "2025-04-20T07:29:44.915051Z"
    },
    "papermill": {
     "duration": 0.016588,
     "end_time": "2025-04-20T07:29:44.917656",
     "exception": false,
     "start_time": "2025-04-20T07:29:44.901068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event_id': 'berlin_wall_fall', 'event_name': 'Fall of the Berlin Wall', 'time_period': 'November 9, 1989', 'location': 'Berlin, Germany', 'description': 'The Fall of the Berlin Wall on November 9, 1989, marked a pivotal moment in world history, signifying the collapse of the Iron Curtain and the end of the Cold War division of Europe. East German authorities unexpectedly announced relaxed travel restrictions, leading thousands of citizens to flock to the wall demanding passage. Overwhelmed border guards eventually opened the gates, allowing euphoric crowds from both sides to unite.  This event triggered widespread celebrations and the eventual dismantling of the wall, symbolizing newfound freedom and the impending reunification of Germany.', 'key_figures': ['GÃ¼nter Schabowski', 'Harald JÃ¤ger', 'Helmut Kohl'], 'perspectives': [{'persona': 'East German University Student', 'experience': 'Growing up in a society with limited freedoms and controlled information, constantly aware of the political divide and longing for opportunities available in the West.', 'daily_life': 'Attending state-sponsored lectures, participating in mandatory ideological training, and secretly discussing Western culture and ideas with friends.', 'challenges': 'Risking expulsion from university or even imprisonment for expressing dissenting views, limited access to Western media, and the frustration of restricted travel.'}, {'persona': 'West Berlin Resident', 'experience': 'Living in an island city surrounded by East Germany, feeling a mix of privilege and isolation, and maintaining connections with family and friends separated by the wall.', 'daily_life': 'Enjoying greater economic prosperity and freedoms but being acutely aware of the stark contrast with the East, and actively engaging in efforts to support and communicate with those on the other side.', 'challenges': 'Limited direct access to family and friends in East Berlin, the psychological weight of living in a divided city, and the potential for increased Cold War tensions.'}, {'persona': 'Border Guard (East German)', 'experience': 'Serving as a symbol of the oppressive regime, torn between loyalty to the state and empathy for citizens seeking freedom and reunification with loved ones.', 'daily_life': 'Enforcing strict border controls, monitoring citizen movements, and dealing with the moral complexities of preventing people from leaving East Germany.', 'challenges': 'Facing growing public discontent and questioning the legitimacy of the regime, managing the stress of potential violence at the border, and the potential for severe consequences for deviating from official orders.'}], 'sensory_details': {'sounds': ['Chanting crowds demanding freedom', 'Hammers and chisels striking the wall', 'Cheers of celebration and disbelief', 'Honking of car horns in celebration', 'The rumble of bulldozers tearing down sections of the wall'], 'visuals': ['Crowds surging towards the checkpoints', 'Graffiti-covered concrete wall being chipped away', 'Families embracing across the newly opened border', 'East Germans crossing into West Berlin for the first time', 'Floodlights illuminating the scene creating a surreal atmosphere'], 'environment': ['Cool November air filled with excitement and anticipation', 'Dust and debris from the crumbling wall', 'Overcrowded streets with people celebrating', 'The stark contrast between the grayness of the East and the colorful lights of the West', 'The smell of exhaust fumes from Trabants mixing with champagne']}, 'historical_context': \"The Berlin Wall, erected in 1961, physically and ideologically divided Berlin, symbolizing the Cold War's broader geopolitical tensions. It represented the suppression of individual liberties in East Germany and the Soviet Bloc. By the late 1980s, the Soviet Union was weakening, and satellite states were experiencing increasing unrest. The 'Prague Spring' of 1968 and the Solidarity movement in Poland had demonstrated a desire for change within the Eastern Bloc, and these desires would manifest into the beginnings of the end of the Berlin wall in November of 1989.\", 'aftermath': 'The fall of the Berlin Wall paved the way for German reunification on October 3, 1990, ending nearly four decades of division. This event had a profound impact on Eastern Europe, contributing to the collapse of communist regimes and the end of the Cold War. The newly unified Germany faced numerous economic and social challenges reintegrating East and West, however, the feeling of unity prevailed.'}\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e594049",
   "metadata": {
    "papermill": {
     "duration": 0.008838,
     "end_time": "2025-04-20T07:29:44.935308",
     "exception": false,
     "start_time": "2025-04-20T07:29:44.926470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare historical documents for the RAG system\n",
    "This dataset is designed to serve as a retrieval base for a RAG system that can answer questions about historyâ€”not just factually, but contextuallyâ€”grounded in real human experiences and primary sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fd3297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:44.954017Z",
     "iopub.status.busy": "2025-04-20T07:29:44.953670Z",
     "iopub.status.idle": "2025-04-20T07:29:44.962487Z",
     "shell.execute_reply": "2025-04-20T07:29:44.961619Z"
    },
    "papermill": {
     "duration": 0.020139,
     "end_time": "2025-04-20T07:29:44.964118",
     "exception": false,
     "start_time": "2025-04-20T07:29:44.943979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_historical_documents(event_data):\n",
    "    documents = []\n",
    "    metadata_list = []\n",
    "    ids = []\n",
    "    i=0\n",
    "    for event in event_data:\n",
    "        i=i+1\n",
    "        \n",
    "        event_name=event[\"event_name\"]  \n",
    "        \n",
    "        combined_text = f\"\"\"\n",
    "        Event: {event.get('event_name')}\n",
    "        Time Period: {event.get('time_period', 'Unknown')}\n",
    "        Location: {event.get('location', 'Unknown')}\n",
    "        \n",
    "        Description: {event.get('description', '')}\n",
    "        \n",
    "        Historical Context: {event.get('historical_context', '')}\n",
    "       \n",
    "        Perspectives:\n",
    "        \"\"\"\n",
    "        \n",
    "        for perspective in event.get('perspectives', []):\n",
    "            combined_text += f\"\"\"\n",
    "            Persona: {perspective.get('persona', '')}\n",
    "            Experience: {perspective.get('experience', '')}\n",
    "            Daily Life: {perspective.get('daily_life', '')}\n",
    "            Challenges: {perspective.get('challenges', '')}\n",
    "            \"\"\"\n",
    "        \n",
    "        combined_text += f\"\"\"\n",
    "        Sensory Details:\n",
    "        Sounds: {', '.join(event.get('sensory_details', {}).get('sounds', []))}\n",
    "        Visuals: {', '.join(event.get('sensory_details', {}).get('visuals', []))}\n",
    "        Environment: {', '.join(event.get('sensory_details', {}).get('environment', []))}\n",
    "        \n",
    "        Aftermath: {event.get('aftermath', '')}\n",
    "        \"\"\"\n",
    "        \n",
    "        documents.append(combined_text)\n",
    "        \n",
    "        metadata_list.append({\n",
    "            \"event_name\": event.get('event_name', event_name),\n",
    "            \"time_period\": event.get('time_period', 'Unknown'),\n",
    "            \"location\": event.get('location', 'Unknown'),\n",
    "            \"key_figures\": event.get('key_figures', []),\n",
    "            \"personas\": [p.get('persona') for p in event.get('perspectives', [])]\n",
    "        })\n",
    "        \n",
    "        \n",
    "        event_id = event.get('event_id', f\"event_{i}\")\n",
    "        ids.append(event_id)\n",
    "        \n",
    "        with open(f\"event_data_{event_id}.json\", \"w\") as f:\n",
    "            json.dump(event, f, indent=2)\n",
    "            \n",
    "    return documents, metadata_list, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4dbb15b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:44.983041Z",
     "iopub.status.busy": "2025-04-20T07:29:44.982309Z",
     "iopub.status.idle": "2025-04-20T07:29:44.990054Z",
     "shell.execute_reply": "2025-04-20T07:29:44.989249Z"
    },
    "papermill": {
     "duration": 0.018487,
     "end_time": "2025-04-20T07:29:44.991532",
     "exception": false,
     "start_time": "2025-04-20T07:29:44.973045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents, metadata_list, ids=prepare_historical_documents(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999780ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.010575Z",
     "iopub.status.busy": "2025-04-20T07:29:45.009576Z",
     "iopub.status.idle": "2025-04-20T07:29:45.087503Z",
     "shell.execute_reply": "2025-04-20T07:29:45.086405Z"
    },
    "papermill": {
     "duration": 0.088801,
     "end_time": "2025-04-20T07:29:45.089018",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.000217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if \"embedContent\" in model.supported_generation_methods:\n",
    "        print(model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e94c536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.107883Z",
     "iopub.status.busy": "2025-04-20T07:29:45.107577Z",
     "iopub.status.idle": "2025-04-20T07:29:45.112415Z",
     "shell.execute_reply": "2025-04-20T07:29:45.111584Z"
    },
    "papermill": {
     "duration": 0.015711,
     "end_time": "2025-04-20T07:29:45.113718",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.098007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gemini_embedding(text, task_type=\"retrieval_document\"):\n",
    "    \n",
    "        result = genai.embed_content(\n",
    "            model=\"models/embedding-001\",\n",
    "            content=text,\n",
    "            task_type=task_type\n",
    "        )\n",
    "        return np.array(result[\"embedding\"], dtype=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad2e87",
   "metadata": {
    "papermill": {
     "duration": 0.008235,
     "end_time": "2025-04-20T07:29:45.130829",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.122594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will set up a RAG pipeline using FAISS to index historical document embeddings and a language model to generate context-aware responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2f7673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.150305Z",
     "iopub.status.busy": "2025-04-20T07:29:45.149949Z",
     "iopub.status.idle": "2025-04-20T07:29:45.157524Z",
     "shell.execute_reply": "2025-04-20T07:29:45.156370Z"
    },
    "papermill": {
     "duration": 0.019234,
     "end_time": "2025-04-20T07:29:45.159201",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.139967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_faiss_rag_system(documents, metadata_list, ids):\n",
    "    \n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        embedding = get_gemini_embedding(doc)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    \n",
    "    embeddings_array = np.array(embeddings, dtype=np.float32)\n",
    "    \n",
    "    dimension = embeddings_array.shape[1]\n",
    "    \n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    \n",
    "    index.add(embeddings_array)\n",
    "    \n",
    "    faiss.write_index(index, \"timeecho_faiss_index.bin\")\n",
    "    \n",
    "    with open(\"timeecho_documents.pkl\", \"wb\") as f:\n",
    "        pickle.dump(documents, f)\n",
    "    \n",
    "    with open(\"timeecho_metadata.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metadata_list, f)\n",
    "    \n",
    "    with open(\"timeecho_ids.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ids, f)\n",
    "   \n",
    "    document_mapping = {\n",
    "        \"documents\": documents,\n",
    "        \"metadata\": metadata_list,\n",
    "        \"ids\": ids\n",
    "    }\n",
    "    \n",
    "    print(f\"Added {len(documents)} documents to the FAISS index\")\n",
    "    return index, document_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66add5d3",
   "metadata": {
    "papermill": {
     "duration": 0.00879,
     "end_time": "2025-04-20T07:29:45.176786",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.167996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the FAISS index and document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08a1e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.197757Z",
     "iopub.status.busy": "2025-04-20T07:29:45.196086Z",
     "iopub.status.idle": "2025-04-20T07:29:45.203350Z",
     "shell.execute_reply": "2025-04-20T07:29:45.202304Z"
    },
    "papermill": {
     "duration": 0.019455,
     "end_time": "2025-04-20T07:29:45.205562",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.186107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_faiss_system():\n",
    "    \n",
    "    index = faiss.read_index(\"timeecho_faiss_index.bin\")\n",
    "    \n",
    "    with open(\"timeecho_documents.pkl\", \"rb\") as f:\n",
    "        documents = pickle.load(f)\n",
    "    \n",
    "    with open(\"timeecho_metadata.pkl\", \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    with open(\"timeecho_ids.pkl\", \"rb\") as f:\n",
    "        ids = pickle.load(f)\n",
    "    \n",
    "    document_mapping = {\n",
    "        \"documents\": documents,\n",
    "        \"metadata\": metadata,\n",
    "        \"ids\": ids\n",
    "    }\n",
    "    \n",
    "    return index, document_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fd61e",
   "metadata": {
    "papermill": {
     "duration": 0.008097,
     "end_time": "2025-04-20T07:29:45.222536",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.214439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Query the FAISS system to retrieve relevant historical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd338bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.241077Z",
     "iopub.status.busy": "2025-04-20T07:29:45.240769Z",
     "iopub.status.idle": "2025-04-20T07:29:45.247371Z",
     "shell.execute_reply": "2025-04-20T07:29:45.246403Z"
    },
    "papermill": {
     "duration": 0.01825,
     "end_time": "2025-04-20T07:29:45.249228",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.230978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_faiss_system(index, document_mapping, query, n_results=3):\n",
    "    \n",
    "    \n",
    "    query_embedding = get_gemini_embedding(query, task_type=\"retrieval_query\")\n",
    "    \n",
    "    query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, n_results)\n",
    "    \n",
    "    \n",
    "    retrieved_documents = []\n",
    "    retrieved_metadata = []\n",
    "    retrieved_ids = []\n",
    "    \n",
    "    for idx in indices[0]:\n",
    "        \n",
    "        if idx >= 0 and idx < len(document_mapping[\"documents\"]):\n",
    "            retrieved_documents.append(document_mapping[\"documents\"][idx])\n",
    "            retrieved_metadata.append(document_mapping[\"metadata\"][idx])\n",
    "            retrieved_ids.append(document_mapping[\"ids\"][idx])\n",
    "    \n",
    "    results = {\n",
    "        \"documents\": retrieved_documents,\n",
    "        \"metadata\": retrieved_metadata,\n",
    "        \"ids\": retrieved_ids,\n",
    "        \"distances\": distances[0].tolist()\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a224913",
   "metadata": {
    "papermill": {
     "duration": 0.008633,
     "end_time": "2025-04-20T07:29:45.338142",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.329509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Generate a complete TimeEcho experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc12f056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.357224Z",
     "iopub.status.busy": "2025-04-20T07:29:45.356902Z",
     "iopub.status.idle": "2025-04-20T07:29:45.364367Z",
     "shell.execute_reply": "2025-04-20T07:29:45.363182Z"
    },
    "papermill": {
     "duration": 0.019122,
     "end_time": "2025-04-20T07:29:45.366027",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.346905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_timeecho_experience(event, persona, rag_results=None):\n",
    "   \n",
    "    \n",
    "    \n",
    "    context = \"\"\n",
    "    if rag_results and len(rag_results['documents']) > 0:\n",
    "        context = \"\\n\\n\".join(rag_results['documents'])\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are TimeEcho, an immersive historical storytelling system. Create a deeply immersive first-person narrative for the following:\n",
    "    \n",
    "    Historical Event: {event}\n",
    "    Persona: {persona}\n",
    "    \n",
    "    {\"Historical Context from Database: \" + context if context else \"\"}\n",
    "    \n",
    "    Generate a complete immersive experience in the following JSON format:\n",
    "    \n",
    "    {{\n",
    "        \"title\": \"A compelling title for this historical experience\",\n",
    "        \"event_summary\": \"A brief factual summary of the event (2-3 sentences)\",\n",
    "        \"persona_details\": {{\n",
    "            \"name\": \"A historically plausible name for this persona\",\n",
    "            \"background\": \"Brief background of this character (2-3 sentences)\"\n",
    "        }},\n",
    "        \"narrative\": \"A detailed first-person narrative from the perspective of the persona experiencing the historical event (700-900 words). Make it emotionally engaging, historically accurate, and immersive.\",\n",
    "        \"sensory_details\": {{\n",
    "            \"sights\": [\"5-7 specific visual elements the persona would see\"],\n",
    "            \"sounds\": [\"5-7 specific sounds the persona would hear\"],\n",
    "            \"smells\": [\"3-5 specific scents present in the environment\"],\n",
    "            \"tactile\": [\"2-3 physical sensations the persona would feel\"]\n",
    "        }},\n",
    "        \"emotional_journey\": [\"5-7 emotional states the persona experiences throughout the event\"],\n",
    "        \"historical_context\": \"Broader historical context for this event (150-200 words)\",\n",
    "        \"media_elements\": {{\n",
    "            \"image_prompts\": [\"3 detailed image generation prompts that would visualize key moments\"],\n",
    "            \"audio_cues\": [\"3 specific sound effect or ambient audio descriptions\"],\n",
    "            \"music_suggestions\": [\"2 styles of music that would enhance the emotional impact\"]\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    Ensure historical accuracy while creating an emotionally resonant experience. Be detailed and specific in your descriptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "           \n",
    "        result = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        experience_data = json.loads(result)\n",
    "        return experience_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating TimeEcho experience: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbcb3f",
   "metadata": {
    "papermill": {
     "duration": 0.008562,
     "end_time": "2025-04-20T07:29:45.383485",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.374923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generate a complete TimeEcho experience\n",
    "This function represents the heart of the TimeEcho experienceâ€”allowing users to engage with history not just as passive observers, but as participants in a dialogue with the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a86eb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.402646Z",
     "iopub.status.busy": "2025-04-20T07:29:45.402295Z",
     "iopub.status.idle": "2025-04-20T07:29:45.409413Z",
     "shell.execute_reply": "2025-04-20T07:29:45.408681Z"
    },
    "papermill": {
     "duration": 0.018416,
     "end_time": "2025-04-20T07:29:45.410795",
     "exception": false,
     "start_time": "2025-04-20T07:29:45.392379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_timeecho_experience(event, persona, rag_results=None):\n",
    "    \n",
    "    \n",
    "    \n",
    "    context = \"\"\n",
    "    if rag_results and len(rag_results['documents']) > 0:\n",
    "        context = \"\\n\\n\".join(rag_results['documents'])\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are TimeEcho, an immersive historical storytelling system. Create a deeply immersive first-person narrative for the following:\n",
    "    \n",
    "    Historical Event: {event}\n",
    "    Persona: {persona}\n",
    "    \n",
    "    {\"Historical Context from Database: \" + context if context else \"\"}\n",
    "    \n",
    "    Generate a complete immersive experience in the following JSON format:\n",
    "    \n",
    "    {{\n",
    "        \"title\": \"A compelling title for this historical experience\",\n",
    "        \"event_summary\": \"A brief factual summary of the event (2-3 sentences)\",\n",
    "        \"persona_details\": {{\n",
    "            \"name\": \"A historically plausible name for this persona\",\n",
    "            \"background\": \"Brief background of this character (2-3 sentences)\"\n",
    "        }},\n",
    "        \"narrative\": \"A detailed first-person narrative from the perspective of the persona experiencing the historical event (700-900 words). Make it emotionally engaging, historically accurate, and immersive.\",\n",
    "        \"sensory_details\": {{\n",
    "            \"sights\": [\"5-7 specific visual elements the persona would see\"],\n",
    "            \"sounds\": [\"5-7 specific sounds the persona would hear\"],\n",
    "            \"smells\": [\"3-5 specific scents present in the environment\"],\n",
    "            \"tactile\": [\"2-3 physical sensations the persona would feel\"]\n",
    "        }},\n",
    "        \"emotional_journey\": [\"5-7 emotional states the persona experiences throughout the event\"],\n",
    "        \"historical_context\": \"Broader historical context for this event (150-200 words)\",\n",
    "        \"media_elements\": {{\n",
    "            \"image_prompts\": [\"3 detailed image generation prompts that would visualize key moments\"],\n",
    "            \"audio_cues\": [\"3 specific sound effect or ambient audio descriptions\"],\n",
    "            \"music_suggestions\": [\"2 styles of music that would enhance the emotional impact\"]\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    Ensure historical accuracy while creating an emotionally resonant experience. Be detailed and specific in your descriptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "        response = model.generate_content(prompt)\n",
    "        #print(\"response: \",response)\n",
    "        #print(\"Done2\")\n",
    "        \n",
    "        result = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        experience_data = json.loads(result)\n",
    "        return experience_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating TimeEcho experience: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff57d657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:29:45.429418Z",
     "iopub.status.busy": "2025-04-20T07:29:45.429060Z",
     "iopub.status.idle": "2025-04-20T07:29:45.434477Z",
     "shell.execute_reply": "2025-04-20T07:29:45.433265Z"
    },
    "papermill": {
     "duration": 0.016224,
     "end_time": "2025-04-20T07:29:45.435751",
     "exception": true,
     "start_time": "2025-04-20T07:29:45.419527",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    index, document_mapping = setup_faiss_rag_system(documents, metadata_list, ids)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def setup_timeecho_rag_faiss():\n",
    "       print(\"Setting up FAISS system...\")\n",
    "    index, document_mapping = setup_faiss_rag_system(documents, metadata_list, ids)\n",
    "    \n",
    "    with open(\"timeecho_collection_info.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"event_ids\": ids,\n",
    "            \"events\": [m[\"event_name\"] for m in metadata_list]\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"TimeEcho FAISS RAG system is ready!\")\n",
    "    return index, document_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67038955",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Handle user requests for TimeEcho experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96745975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:17.934074Z",
     "iopub.status.busy": "2025-04-20T06:28:17.933659Z",
     "iopub.status.idle": "2025-04-20T06:28:17.953337Z",
     "shell.execute_reply": "2025-04-20T06:28:17.952221Z",
     "shell.execute_reply.started": "2025-04-20T06:28:17.934046Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeecho_experience_handler(index, document_mapping, event, persona):\n",
    "    \n",
    "   \n",
    "    query = f\"Event: {event} Persona: {persona}\"\n",
    "    rag_results = query_faiss_system(index, document_mapping, query)\n",
    "    \n",
    "   \n",
    "    if rag_results[\"distances\"] and rag_results[\"distances\"][0] < 1.0:  \n",
    "        \n",
    "        experience = generate_timeecho_experience(event, persona, rag_results)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        experience = generate_timeecho_experience(event, persona)\n",
    "    \n",
    "    return experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8982036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:17.955189Z",
     "iopub.status.busy": "2025-04-20T06:28:17.954433Z",
     "iopub.status.idle": "2025-04-20T06:28:17.979765Z",
     "shell.execute_reply": "2025-04-20T06:28:17.978657Z",
     "shell.execute_reply.started": "2025-04-20T06:28:17.955156Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_image_input(image_file):\n",
    "    try:\n",
    "        img=image_file\n",
    "        model=genai.GenerativeModel('gemini-2.0-flash')\n",
    "        image_parts=image_parts = [{\"mime_type\": \"image/jpeg\", \"data\": image_to_bytes(img)}]\n",
    "        prompt = \"\"\"\n",
    "        Analyze this historical image and extract the following information:\n",
    "        1. What historical event or time period does this image likely depict?\n",
    "        2. What are the key visual elements, people, or artifacts visible?\n",
    "        3. What historical context can you derive from this image?\n",
    "        \n",
    "        Format your response as JSON:\n",
    "        {\n",
    "            \"event\": \"Name of the identified historical event or period\",\n",
    "            \"time_period\": \"Approximate year or date range\",\n",
    "            \"location\": \"Likely geographical location\",\n",
    "            \"key_elements\": [\"List of 3-5 important visual elements\"],\n",
    "            \"historical_context\": \"Brief historical context (2-3 sentences)\"\n",
    "        }\n",
    "        \"\"\"\n",
    "        response = model.generate_content([prompt, image_parts[0]])\n",
    "        json_match = re.search(r'```json\\s*(.*?)\\s*```', response.text, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group(1))\n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "                result = json.loads(response.text)\n",
    "                print(result)\n",
    "            except:\n",
    "                \n",
    "                result = {\n",
    "                    \"event\": \"Unknown\",\n",
    "                    \"time_period\": \"Unknown\",\n",
    "                    \"location\": \"Unknown\",\n",
    "                    \"key_elements\": [],\n",
    "                    \"historical_context\": response.text[:200]\n",
    "                }\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return {\n",
    "            \"event\": \"Error analyzing image\",\n",
    "            \"time_period\": \"Unknown\",\n",
    "            \"location\": \"Unknown\",\n",
    "            \"key_elements\": [],\n",
    "            \"historical_context\": f\"Error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550d31c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:17.981280Z",
     "iopub.status.busy": "2025-04-20T06:28:17.980921Z",
     "iopub.status.idle": "2025-04-20T06:28:18.003499Z",
     "shell.execute_reply": "2025-04-20T06:28:18.002058Z",
     "shell.execute_reply.started": "2025-04-20T06:28:17.981251Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_bytes(image):\n",
    "    \"\"\"Convert PIL Image to bytes\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return buffered.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31554eb0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Generate speech from text with voice variations based on persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23265a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:18.004951Z",
     "iopub.status.busy": "2025-04-20T06:28:18.004651Z",
     "iopub.status.idle": "2025-04-20T06:28:18.025090Z",
     "shell.execute_reply": "2025-04-20T06:28:18.024201Z",
     "shell.execute_reply.started": "2025-04-20T06:28:18.004926Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "def generate_speech(text, voice_type=\"neutral\"):\n",
    "    \n",
    "    try:\n",
    "        # Map voice_type to gTTS language and properties\n",
    "        voice_mapping = {\n",
    "            \"neutral\": {\"lang\": \"en\", \"tld\": \"com\"},\n",
    "            \"british\": {\"lang\": \"en\", \"tld\": \"co.uk\"},\n",
    "            \"american\": {\"lang\": \"en\", \"tld\": \"us\"},\n",
    "            \"french_accent\": {\"lang\": \"en\", \"tld\": \"ie\"},  \n",
    "            \"german_accent\": {\"lang\": \"en\", \"tld\": \"ca\"},  \n",
    "            \"elderly\": {\"lang\": \"en\", \"tld\": \"com.au\"}, \n",
    "            \"child\": {\"lang\": \"en\", \"tld\": \"co.in\"},  \n",
    "        }\n",
    "        voice_settings = voice_mapping.get(voice_type.lower(), voice_mapping[\"neutral\"])\n",
    "        tts = gTTS(text=text, lang=voice_settings[\"lang\"], tld=voice_settings[\"tld\"], slow=False)\n",
    "        temp_file = f\"temp_speech_{voice_type}.mp3\"\n",
    "        tts.save(temp_file)\n",
    "        \n",
    "        display(Audio(temp_file, autoplay=False))\n",
    "        \n",
    "        return temp_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating speech: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38597177",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Extract the historical event and persona from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a215f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:18.026716Z",
     "iopub.status.busy": "2025-04-20T06:28:18.026341Z",
     "iopub.status.idle": "2025-04-20T06:28:18.047697Z",
     "shell.execute_reply": "2025-04-20T06:28:18.046934Z",
     "shell.execute_reply.started": "2025-04-20T06:28:18.026693Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_event_and_persona(query):\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this query about a historical event and extract:\n",
    "        1. The specific historical event being referenced\n",
    "        2. The persona or viewpoint requested (if any)\n",
    "        3. The type of information being requested\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Format your response as JSON:\n",
    "        {{\n",
    "            \"event\": \"Name of the historical event (or 'unknown' if not specified)\",\n",
    "            \"persona\": \"The requested persona/viewpoint (or 'general' if not specified)\",\n",
    "            \"request_type\": \"narrative|factual|sensory|comparison\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "            response = model.generate_content(prompt)\n",
    "            result = json.loads(response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting event and persona: {e}\")\n",
    "            \n",
    "            words = query.lower().split()\n",
    "            event_keywords = [\"war\", \"revolution\", \"independence\", \"battle\", \"fall\", \"crisis\"]\n",
    "            \n",
    "            event = \"unknown\"\n",
    "            for kw in event_keywords:\n",
    "                if kw in words:\n",
    "                    start_idx = max(0, words.index(kw) - 3)\n",
    "                    end_idx = min(len(words), words.index(kw) + 4)\n",
    "                    event = \" \".join(words[start_idx:end_idx])\n",
    "                    break\n",
    "                    \n",
    "            return {\n",
    "                \"event\": event,\n",
    "                \"persona\": \"general\",\n",
    "                \"request_type\": \"narrative\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653eb2c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Generate a historical narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21def600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:18.049123Z",
     "iopub.status.busy": "2025-04-20T06:28:18.048819Z",
     "iopub.status.idle": "2025-04-20T06:28:22.126311Z",
     "shell.execute_reply": "2025-04-20T06:28:22.125225Z",
     "shell.execute_reply.started": "2025-04-20T06:28:18.049096Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gtts\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "def generate_narrative(event, persona, rag_results=None):\n",
    "        \n",
    "       \n",
    "        context = \"\"\n",
    "        if rag_results and len(rag_results['documents']) > 0:\n",
    "            context = \"\\n\\n\".join(rag_results['documents'])\n",
    "            \n",
    "        \n",
    "        voice_type = \"neutral\"\n",
    "        if \"soldier\" in persona.lower() or \"warrior\" in persona.lower():\n",
    "            voice_type = \"american\"\n",
    "        elif \"noble\" in persona.lower() or \"aristocrat\" in persona.lower():\n",
    "            voice_type = \"british\"\n",
    "        elif \"child\" in persona.lower():\n",
    "            voice_type = \"child\"\n",
    "        elif \"elder\" in persona.lower() or \"old\" in persona.lower():\n",
    "            voice_type = \"elderly\"\n",
    "        elif any(nationality in persona.lower() for nationality in [\"french\", \"france\"]):\n",
    "            voice_type = \"french_accent\"\n",
    "        elif any(nationality in persona.lower() for nationality in [\"german\", \"germany\"]):\n",
    "            voice_type = \"german_accent\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are TimeEcho, an immersive historical storytelling system. Create a deeply immersive first-person narrative for the following:\n",
    "        \n",
    "        Historical Event: {event}\n",
    "        Persona: {persona}\n",
    "        \n",
    "        {\"Historical Context from Database: \" + context if context else \"\"}\n",
    "        \n",
    "        Generate a complete immersive experience in the following JSON format:\n",
    "        \n",
    "        {{\n",
    "            \"title\": \"A compelling title for this historical experience\",\n",
    "            \"event_summary\": \"A brief factual summary of the event (2-3 sentences)\",\n",
    "            \"persona_details\": {{\n",
    "                \"name\": \"A historically plausible name for this persona\",\n",
    "                \"background\": \"Brief background of this character (2-3 sentences)\",\n",
    "                \"voice\": \"{voice_type}\"\n",
    "            }},\n",
    "            \"narrative\": \"A detailed first-person narrative from the perspective of the persona experiencing the historical event (500-700 words). Make it emotionally engaging, historically accurate, and immersive.\",\n",
    "            \"sensory_details\": {{\n",
    "                \"sights\": [\"5-7 specific visual elements the persona would see\"],\n",
    "                \"sounds\": [\"5-7 specific sounds the persona would hear\"],\n",
    "                \"smells\": [\"3-5 specific scents present in the environment\"],\n",
    "                \"tactile\": [\"2-3 physical sensations the persona would feel\"]\n",
    "            }},\n",
    "            \"emotional_journey\": [\"5-7 emotional states the persona experiences throughout the event\"],\n",
    "            \"historical_context\": \"Broader historical context for this event (150-200 words)\",\n",
    "            \"media_elements\": {{\n",
    "                \"image_prompts\": [\"3 detailed image generation prompts that would visualize key moments\"],\n",
    "                \"audio_cues\": [\"3 specific sound effect or ambient audio descriptions\"],\n",
    "                \"music_suggestions\": [\"2 styles of music that would enhance the emotional impact\"]\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Ensure historical accuracy while creating an emotionally resonant experience. Be detailed and specific in your descriptions.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = gemini_model.generate_content(prompt)\n",
    "            result = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            experience_data = json.loads(result)\n",
    "            \n",
    "            \n",
    "            if \"persona_details\" in experience_data and \"voice\" not in experience_data[\"persona_details\"]:\n",
    "                experience_data[\"persona_details\"][\"voice\"] = voice_type\n",
    "                \n",
    "            return experience_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating TimeEcho experience: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa73401",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Process a user query and generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca525080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:22.128048Z",
     "iopub.status.busy": "2025-04-20T06:28:22.127687Z",
     "iopub.status.idle": "2025-04-20T06:28:22.141742Z",
     "shell.execute_reply": "2025-04-20T06:28:22.140856Z",
     "shell.execute_reply.started": "2025-04-20T06:28:22.128007Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_query(query, image_file=None):\n",
    "        \n",
    "        \n",
    "        conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "     \n",
    "        image_analysis = None\n",
    "        if image_file:\n",
    "            image_analysis = process_image_input(image_file)\n",
    "            print(\"Image Analysis:\")\n",
    "            print(json.dumps(image_analysis, indent=2))\n",
    "        \n",
    "        \n",
    "        query_analysis = extract_event_and_persona(query)\n",
    "        event = query_analysis[\"event\"]\n",
    "        persona = query_analysis[\"persona\"]\n",
    "        request_type = query_analysis[\"request_type\"]\n",
    "       \n",
    "        if image_analysis and image_analysis[\"event\"] != \"Unknown\":\n",
    "            if event == \"unknown\":\n",
    "                event = image_analysis[\"event\"]\n",
    "      \n",
    "            query += f\" Additional context: The image shows {image_analysis['event']} from {image_analysis['time_period']} in {image_analysis['location']}.\"\n",
    "        \n",
    "\n",
    "        rag_results = query_rag(query)\n",
    "        \n",
    "        if request_type == \"factual\":\n",
    "            response = generate_factual_response(query, rag_results)\n",
    "            response_data = {\"type\": \"factual\", \"content\": response}\n",
    "        else:\n",
    "            \n",
    "            experience = generate_narrative(event, persona, rag_results)\n",
    "            \n",
    "            \n",
    "            image_files = []\n",
    "            if experience and \"media_elements\" in experience and \"image_prompts\" in experience[\"media_elements\"]:\n",
    "                for i, prompt in enumerate(experience[\"media_elements\"][\"image_prompts\"]):\n",
    "                    if i < 1:  \n",
    "                        image_file = generate_historical_image(prompt)\n",
    "                        if image_file:\n",
    "                            image_files.append(image_file)\n",
    "            \n",
    "           \n",
    "            speech_file = None\n",
    "            if experience and \"narrative\" in experience:\n",
    "                voice_type = \"neutral\"\n",
    "                if \"persona_details\" in experience and \"voice\" in experience[\"persona_details\"]:\n",
    "                    voice_type = experience[\"persona_details\"][\"voice\"]\n",
    "                \n",
    "                \n",
    "                narrative_text = experience[\"narrative\"]\n",
    "                speech_excerpt = \" \".join(narrative_text.split()[:100])  \n",
    "                speech_file = generate_speech(speech_excerpt, voice_type)\n",
    "            \n",
    "            response_data = {\n",
    "                \"type\": \"narrative\",\n",
    "                \"experience\": experience,\n",
    "                \"image_files\": image_files,\n",
    "                \"speech_file\": speech_file\n",
    "            }\n",
    "        \n",
    "       \n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": json.dumps(response_data)})\n",
    "        \n",
    "        return response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea5ff7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Generate a factual response to a historical query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fa92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:28:22.142881Z",
     "iopub.status.busy": "2025-04-20T06:28:22.142645Z",
     "iopub.status.idle": "2025-04-20T06:28:22.168863Z",
     "shell.execute_reply": "2025-04-20T06:28:22.167932Z",
     "shell.execute_reply.started": "2025-04-20T06:28:22.142863Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_factual_response(query, rag_results):\n",
    "        \n",
    "        context = \"\"\n",
    "        if rag_results and len(rag_results['documents']) > 0:\n",
    "            context = \"\\n\\n\".join(rag_results['documents'])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        As TimeEcho, a historical information system, provide an accurate and informative response to this query:\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        {\"Based on the following historical information:\" + context if context else \"Using your historical knowledge:\"}\n",
    "        \n",
    "        Provide a well-structured, factual response that is historically accurate and answers the query directly.\n",
    "        Include key dates, figures, and relevant context. Format your response in clear paragraphs.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = gemini_model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating factual response: {e}\")\n",
    "            return \"I'm sorry, I couldn't generate a response to your historical query.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534880ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Main function to run the TimeEcho system in Kaggle environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf6ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T06:44:44.750645Z",
     "iopub.status.busy": "2025-04-20T06:44:44.749921Z",
     "iopub.status.idle": "2025-04-20T06:44:58.136648Z",
     "shell.execute_reply": "2025-04-20T06:44:58.135815Z",
     "shell.execute_reply.started": "2025-04-20T06:44:44.750616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print(\"ðŸ•°ï¸ Initializing TimeEcho - Immersive Historical Storytelling System...\")\n",
    "    \n",
    "    \n",
    "    if os.path.exists(\"timeecho_faiss_index.bin\"):\n",
    "        print(\"Loading existing FAISS index...\")\n",
    "        index, document_mapping = load_faiss_system()\n",
    "    else:\n",
    "        \n",
    "        print(\"Setting up new FAISS index...\")\n",
    "        index, document_mapping = setup_timeecho_rag_faiss()\n",
    "    \n",
    "    def process_historical_query(query, image_file=None):\n",
    "        print(f\"Processing query: {query}\")\n",
    "        \n",
    "        \n",
    "        if image_file:\n",
    "            image_analysis = process_image_input(image_file)\n",
    "            print(\"\\nImage Analysis:\")\n",
    "            print(json.dumps(image_analysis, indent=2))\n",
    "            \n",
    "            \n",
    "            if image_analysis[\"event\"] != \"Unknown\":\n",
    "                query += f\" Additional context: The image shows {image_analysis['event']} from {image_analysis['time_period']}.\"\n",
    "        \n",
    "        result = extract_event_and_persona(query)\n",
    "        event=result['event']\n",
    "        persona=result['persona']\n",
    "        request_type=result['request_type']\n",
    "        print(f\"\\nIdentified Event: {event}\")\n",
    "        print(f\"Identified Persona: {persona}\")\n",
    "        print(f\"Request Type: {request_type}\")\n",
    "        \n",
    "        \n",
    "        rag_results = query_faiss_system(index, document_mapping, query)\n",
    "        \n",
    "        \n",
    "        if request_type == \"factual\":\n",
    "            \n",
    "            factual_response = generate_factual_response(query, rag_results)\n",
    "            print(\"\\nðŸ“š Historical Information:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(factual_response)\n",
    "            return {\"type\": \"factual\", \"content\": factual_response}\n",
    "        else:\n",
    "            \n",
    "            experience = timeecho_experience_handler(index, document_mapping, event, persona)\n",
    "            \n",
    "            if experience:\n",
    "                print(f\"\\nðŸ•°ï¸ TimeEcho Experience: {experience['title']}\")\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"Historical Event: {experience['event_summary']}\")\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"Through the eyes of: {experience['persona_details']['name']} - {experience['persona_details']['background']}\")\n",
    "                \n",
    "           \n",
    "                # image_file = None\n",
    "                # if \"media_elements\" in experience and \"image_prompts\" in experience[\"media_elements\"]:\n",
    "                #     prompt = experience[\"media_elements\"][\"image_prompts\"][0]\n",
    "                #     print(\"\\nðŸ–¼ï¸ Generating historical visualization...\")\n",
    "                #     image_file = generate_historical_image(prompt)\n",
    "                #     print(image_file)\n",
    "                #     display(IPImage(filename=image_file))\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                speech_file = None\n",
    "                if \"narrative\" in experience:\n",
    "                    voice_type = \"neutral\"\n",
    "                    if \"persona_details\" in experience and \"voice\" in experience.get(\"persona_details\", {}):\n",
    "                        voice_type = experience[\"persona_details\"][\"voice\"]\n",
    "                    \n",
    "                    \n",
    "                    narrative_text = experience[\"narrative\"]\n",
    "                    speech_excerpt = \" \".join(narrative_text.split()[:100])  \n",
    "                    print(\"\\nðŸ”Š Generating narrative speech...\")\n",
    "                    speech_file = generate_speech(speech_excerpt, voice_type)\n",
    "                \n",
    "                print(\"\\nðŸ“œ Narrative:\")\n",
    "                print(experience['narrative'])\n",
    "                print(\"-\" * 80)\n",
    "                print(\"Sensory Details:\")\n",
    "                print(\"ðŸ‘ï¸ Sights:\", \", \".join(experience['sensory_details']['sights']))\n",
    "                print(\"ðŸ‘‚ Sounds:\", \", \".join(experience['sensory_details']['sounds']))\n",
    "                print(\"ðŸ‘ƒ Smells:\", \", \".join(experience['sensory_details']['smells']))\n",
    "                print(\"ðŸ–ï¸ Tactile:\", \", \".join(experience['sensory_details']['tactile']))\n",
    "                print(\"-\" * 80)\n",
    "                print(\"Historical Context:\")\n",
    "                print(experience['historical_context'])\n",
    "                \n",
    "                return {\n",
    "                    \"type\": \"narrative\",\n",
    "                    \"experience\": experience,\n",
    "                    \"image_file\": image_file,\n",
    "                    \"speech_file\": speech_file\n",
    "                }\n",
    "            else:\n",
    "                print(\"Failed to generate a complete historical experience.\")\n",
    "                return {\"type\": \"error\", \"message\": \"Failed to generate experience\"}\n",
    "    \n",
    "    \n",
    "    print(\"\\n=== TimeEcho System Ready ===\")\n",
    "    print(\"You can now use the process_historical_query function with any query\")\n",
    "    print(\"Example: result = process_historical_query('Tell me about World War II from a soldier's perspective')\")\n",
    "    \n",
    "    sample_query = \"Tell me about the Fall of the Berlin Wall from the perspective of an East German citizen\"\n",
    "    print(f\"\\nRunning test query: '{sample_query}'\")\n",
    "    result = process_historical_query(sample_query)\n",
    "    \n",
    "    return {\n",
    "        \"index\": index,\n",
    "        \"document_mapping\": document_mapping,\n",
    "        \"process_query\": process_historical_query \n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    timeecho_system = main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b5723",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "ðŸ§­ Conclusion\n",
    "History is more than a timeline of eventsâ€”it's a mosaic of lived experiences, emotions, and untold stories. With TimeEcho, the goal is not just to present history, but to humanize itâ€”transforming passive information into immersive moments that bridge the gap between past and present.\n",
    "\n",
    "By blending data, narrative, and interactive design, we can create tools that donâ€™t just teach history, but allow us to feel it. TimeEcho is a step toward that visionâ€”a future where technology deepens our connection to the human stories that shaped our world.\n",
    "\n",
    "This is just the beginning. As we continue to explore the intersection of storytelling and data, one thing becomes clear: the past has a voice. And it's time we listened.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7bb6e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Numbers tell part of the story. But to truly feel the heartbeat of the past, we need narrative, emotion, and vision. I wrote a blog post capturing the essence behind this projectâ€”why it matters, and what it could mean.\n",
    "\n",
    "Read it here â†’ [TimeEcho on Medium](http://https://medium.com/@stuti2718/timeecho-experience-history-through-the-eyes-of-those-who-lived-it-744c0beda0c6)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 135.275118,
   "end_time": "2025-04-20T07:29:48.668654",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T07:27:33.393536",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
